# 基于深度强化学习的供应链库存管理策略对比研究

## 📋 项目概述

本项目实现了一个基于深度强化学习的供应链库存管理仿真系统，对比研究了三种不同的DQN算法在经典"啤酒博弈"问题中的表现：

- **基线DQN**：标准深度Q网络算法
- **Double DQN**：改进的Double DQN算法，解决Q值过估计问题
- **IDQN多智能体**：独立学习的多智能体系统，能够观察到牛鞭效应的涌现

## 🎯 研究意义

### 核心贡献
1. **算法对比验证**：验证了Double DQN相对于标准DQN的性能优势
2. **牛鞭效应模拟**：多智能体系统自发涌现出经典的供应链牛鞭效应
3. **结构性洞察**：发现供应链中游企业在非合作博弈中的劣势地位

### 应用价值
- 为智慧供应链管理提供AI决策工具
- 模拟复杂经济系统的涌现行为
- 为企业供应链定位策略提供指导

## 🏗️ 系统架构

```
供应链结构: 制造商 → 分销商 → 零售商 → 终端客户
           (企业2)   (企业1)   (企业0)

智能体类型:
├── DQNAgent (基线)
├── DoubleDQNAgent (改进)  
└── IDQN System (多智能体)
```

## 🚀 快速开始

### 环境要求
```bash
Python
torch
numpy
matplotlib
```

### 安装依赖
```bash
pip install torch numpy matplotlib
```

### 运行实验
```bash
python my_dqn.py
```

程序将自动运行三个实验：
1. **基线DQN训练**（2000回合）
2. **Double DQN训练**（2000回合）
3. **多智能体IDQN训练**（2000回合）

## 📊 实验结果

### 性能对比
| 算法 | 平均测试得分 | 学习稳定性 | 特殊现象 |
|------|-------------|-----------|----------|
| 基线DQN | 1073.65 | 中等 | - |
| Double DQN | 1180.65 | 优秀 | 更平滑收敛 |
| IDQN系统 | 4933.45 | 良好 | 牛鞭效应涌现 |

### 关键发现
1. **Double DQN优势明显**：相比基线DQN提升约10%性能
2. **牛鞭效应自发涌现**：订单波动沿供应链逐级放大
3. **中间商困境**：中游企业获得最低平均奖励(926.55)

## 📁 文件结构

```
├── my_dqn.py              # 主要实现代码
├── course_dqn_example.py  # 原始参考代码
├── models/                # 保存的模型文件
│   ├── DQNAgent_firm_1.pth
│   ├── DoubleDQNAgent_firm_1.pth
│   └── IDQN_firm_*.pth
├── figures/               # 生成的图表
│   ├── 学习曲线对比.png
│   ├── 策略对比图.png
│   └── 综合性能分析.png
└── README.md             # 项目说明
```

## 🔧 核心功能

### 1. 环境建模
- **状态空间**：[订单量, 满足需求, 库存水平]
- **动作空间**：离散订单量 [1, 30]
- **奖励函数**：利润 = 销售收入 - 采购成本 - 库存成本 - 缺货成本

### 2. 智能体算法
- **DQN网络**：3层MLP (输入3 → 128 → 128 → 输出30)
- **经验回放**：缓冲区大小10000
- **目标网络**：软更新(τ=0.001)

### 3. 可视化分析
- **学习曲线**：训练过程奖励变化
- **策略对比**：不同算法的决策行为
- **多维分析**：库存、订单、需求等指标

## 📈 使用说明

### 自定义参数
```python
# 在my_dqn.py中修改以下参数
NUM_FIRMS = 3           # 企业数量
NUM_EPISODES = 2000     # 训练回合数
STATE_SIZE = 3          # 状态维度
ACTION_SIZE = 30        # 动作空间大小
```

### 单独运行某个算法
```python
# 只运行Double DQN
agent = DoubleDQNAgent(STATE_SIZE, ACTION_SIZE, firm_id=1)
scores = train_single_agent(env, agent)
```

### 加载预训练模型
```python
agent = DoubleDQNAgent(STATE_SIZE, ACTION_SIZE, firm_id=1)
agent.load('models/DoubleDQNAgent_firm_1.pth')
```

## 🎨 可视化功能

### 学习曲线对比
显示三种算法的训练进度和收敛情况

### 策略行为分析
对比不同算法的订购决策模式

### 多智能体系统分析
- 系统总奖励和个体奖励
- 各企业库存变化
- 订单量波动对比
- 需求满足率分析

## 🔬 研究洞察

### 牛鞭效应机制
```
终端需求(泊松分布) → 零售商订单 → 分销商订单 → 制造商订单
    波动幅度：      小      →     中      →     大
```

### 企业位置影响
- **上游优势**：制造商获得最高奖励(2394.50)
- **中游劣势**：分销商获得最低奖励(926.55)
- **下游稳定**：零售商获得中等奖励(1612.40)